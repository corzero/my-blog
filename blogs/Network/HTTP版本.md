---
title: HTTP各个版本
date: 2021-06-12
tags:
  - Http
categories:
  - Network
---

## 前言

浏览器中的⽹络，就避不开 HTTP。绝大部分前端工程师知道 HTTP 是浏览器中最重要且使⽤最多的协议，是浏览器和服务器之间的通信语⾔，也是互联⽹的基⽯。⽽随着浏览器的发展，HTTP 为了能适应新的形式也在持续进化，但在开发过程中不会特别在意 HTTP 版本问题，而且绝大多数的网站使用的都是 HTTP1.1 的版本内容，因为业务复杂度不高，对这些没有需求，但随着前后端的迅速发展，前后端的通信也越来越多，前端需要的数据也越来越多，网络成了制约前端获取数据性能的一大问题，那么什么样的版本会给现有项目带来更高性能的体验呢？我们需要对各个版本的 HTTP 有一定的了解，才能正确选择，为项目优化添砖加瓦。

## HTTP 1.0

⾸先我们来看看诞⽣最早的 HTTP0.9。HTTP0.9 是于 1991 年提出的，主要⽤于学术交流，需求很简单⸺⽤来在⽹络之间**传递 HTML 超⽂本的内容**，所以被称为超⽂本传输协议。整体来看，它的实现也很简单，采⽤了基于请求响应的模式，从客⼾端发出请求，服务器返回数据。

<img :src="$withBase('/image/HTTP0.9.png')" alt="HTTP0.9" />

- 因为 HTTP 都是基于 TCP 协议的，所以客⼾端先要根据 IP 地址、端⼝和服务器建⽴ TCP 连接，⽽建⽴连接的过程就是 TCP 协议三次握⼿的过程。
- 建⽴好连接之后，会发送⼀个 GET 请求⾏的信息，如 GET /index.html ⽤来获取 index.html。
- 服务器接收请求信息之后，读取对应的 HTML ⽂件，并将数据以 ASCII 字符流返回给客⼾端。HTML ⽂档传输完成后，断开连接。

而随后的几年里 HTTP/0.9 已经不能适⽤新兴⽹络的发展，所以这时就需要⼀个新的协议来⽀撑新兴⽹络，这就是 HTTP1.0 诞⽣的原因。⾸先在浏览器中展⽰的不单是 HTML ⽂件了，还包括了**JavaScript、CSS、图⽚、⾳频、视频等不同类型的⽂件**。因此⽀持多种类型的⽂件下载是 HTTP1.0 的⼀个核⼼诉求，⽽且⽂件格式不仅仅局限于 ASCII 编码，还有很多其他类型编码的⽂件。

**该如何实现多种类型⽂件的下载呢？**

HTTP 是浏览器和服务器之间的通信语⾔，不过 HTTP/0.9 在建⽴好连接之后，只会发送
类似 GET /index.html 的简单请求命令，并没有其他途径告诉服务器更多的信息，如⽂件编码、⽂件类型等。同样，服务器是直接返回数据给浏览器的，也没有其他途径告诉浏览器更多的关于服务器返回的⽂件信息。

这种简单的交流型形式⽆疑不能满⾜传输多种类型⽂件的需求，那为了让客⼾端和服务器能更深⼊地交流，HTTP1.0 引⼊了请求头和响应头，它们都是以为 Key-Value 形式保存的，在 HTTP 发送请求时，会带上请求头信息，服务器返回数据时，会先返回响应头信息。⾄于 HTTP1.0 具体的请求流程，可以参考下图。

<img :src="$withBase('/image/HTTP1.0.png')" alt="HTTP1.0" />

为了支持不同的数据类型，HTTP1.0 是通过设置请求头和响应头来确定。

- ⾸先，浏览器需要知道服务器返回的数据是什么类型的，然后浏览器才能根据不同的数据类型做针对性的处理。
- 其次，由于万维⽹所⽀持的应⽤变得越来越⼴，所以单个⽂件的数据量也变得越来越⼤。为了减轻传输性能，服务器会对数据进⾏压缩后再传输，所以浏览器需要知道服务器压缩的⽅法。
- 再次，由于万维⽹是⽀持全球范围的，所以需要提供国际化的⽀持，服务器需要对不同的地区提供不同的语⾔版本，这就需要浏览器告诉服务器它想要什么语⾔版本的⻚⾯。

- 最后，由于增加了各种不同类型的⽂件，⽽每种⽂件的编码形式⼜可能不⼀样，为了能够准确地读取⽂件，浏览器需要知道⽂件的编码类型。

基于以上问题，HTTP1.0 的⽅案是通过请求头和响应头来进⾏协商，在发起请求时候会通过 HTTP 请求头告诉服务器它期待服务器返回什么类型的⽂件、采取什么形式的压缩、提供什么语⾔的⽂件以及⽂件的具体编码。最终发送出来的请求头内容如下：

```js
accept: text/html
accept-encoding: gzip, deflate, br
accept-Charset: ISO-8859-1,utf-8
accept-language: zh-CN,zh
```

其中第⼀⾏表⽰期望服务器返回 html 类型的⽂件，第⼆⾏表⽰期望服务器可以采⽤ gzip、deflate 或者 br 其中的⼀种压缩⽅式，第三⾏表⽰期望返回的⽂件编码是 UTF-8 或者 ISO-8859-1，第四⾏是表⽰期望⻚⾯的优先语⾔是中⽂。

服务器接收到浏览器发送过来的请求头信息之后，会根据请求头的信息来准备响应数据。不过有时候会有⼀些意外情况发⽣，⽐如浏览器请求的压缩类型是 gzip，但是服务器不⽀持 gzip，只⽀持 br 压缩，那么它会通过响应头中的 content-encoding 字段告诉浏览器最终的压缩类型，也就是说最终浏览器需要根据响应头的信息来处理数据。下⾯是⼀段响应头的数据信息：

```js
content-encoding: br
content-type: text/html; charset=UTF-8
```

其中第⼀⾏表⽰服务器采⽤了 br 的压缩⽅法，第⼆⾏表⽰服务器返回的是 html ⽂件，并且该⽂件的编码类型是 UTF-8。

有了响应头的信息，浏览器就会使⽤ br ⽅法来解压⽂件，再按照 UTF-8 的编码格式来处理原始⽂件，最后按照 HTML 的⽅式来解析该⽂件。这就是 HTTP1.0 ⽀持多⽂件的⼀个基本的处理流程。

HTTP1.0 除了对多⽂件提供良好的⽀持外，还依据当时实际的需求引⼊了很多其他的特性，这些特性都是通过请求头和响应头来实现的。下⾯我们来看看新增的⼏个典型的特性：

- 有的请求服务器可能⽆法处理，或者处理出错，这时候就需要告诉浏览器服务器最终处理该请求的情况，这就引⼊了*\*\*状态码*。状态码是通过响应⾏的⽅式来通知浏览器的。

- 为了减轻服务器的压⼒，在 HTTP1.0 中提供了**Cache 机制**，⽤来缓存已经下载过的数据.

- 服务器需要统计客⼾端的基础信息，⽐如 Windows 和 macOS 的⽤⼾数量分别是多少，所以 HTTP1.0 的请求头中还加⼊了**⽤⼾代理的字段**。

## HTTP1.1: 1.0 的增强版

我们看一下增强了什么：

1. 改进持久连接

HTTP1.0 每进⾏⼀次 HTTP 通信，都需要经历建⽴ TCP 连接、传输 HTTP 数据和断开 TCP 连接三个阶段。

<img :src="$withBase('/image/HTTP1.0短连接.png')" alt="HTTP1.0短连接" height="300"/>

在当时，由于通信的⽂件⽐较⼩，⽽且每个⻚⾯的引⽤也不多，所以这种传输形式没什么⼤问题。但是随着浏览器普及，单个⻚⾯中的图⽚⽂件越来越多，有时候⼀个⻚⾯可能包含了⼏百个外部引⽤的资源⽂件，如果在下载每个⽂件的时候，都需要经历建⽴ TCP 连接、传输数据和断开连接这样的步骤，⽆疑会增加⼤量⽆谓的开销。

为了解决这个问题，HTTP1.1 中通过设置`Connection: keep-alive`增加了长连接的⽅法，它的特点是在⼀个 TCP 连接上可以传输多个 HTTP 请求，只要浏览器或者服务器没有明确断开连接，那么该 TCP 连接会⼀直保持

<img :src="$withBase('/image/HTTP1.1长连接.png')" alt="HTTP1.1长连接" height="300"/>

持久连接在 HTTP1.1 中是默认开启的，所以不需要专⻔为了持久连接去 HTTP 请求头设置信息，如果不想要采⽤持久连接，可以在 HTTP 请求头中加上`Connection: close`。⽬前浏览器中对于同⼀个域名，默认允许同时建⽴ 6 个 TCP 持久连接。

2. 不怎么使用的 HTTP 管线化

持久连接虽然能减少 TCP 的建⽴和断开次数，但是它需要等待前⾯的请求返回之后，才能进⾏下⼀次请求。如果 TCP 通道中的某个请求因为某些原因没有及时返回，那么就会阻塞后⾯的所有请求，这就是著名的**队头阻塞**的问题。

HTTP1.1 中试图通过管线化的技术来解决队头阻塞的问题。HTTP1.1 中的管线化是指将多个 HTTP 请求整批提交给服务器的技术，虽然可以整批发送请求，不过服务器依然需要根据请求顺序来回复浏览器的请求。

但是不同的浏览器在管线化技术上有不同的差异，导致我们在开发过程中很少使用它。

3. 提供虚拟主机的⽀持

在 HTTP1.0 中，每个域名绑定了⼀个唯⼀的 IP 地址，因此⼀个服务器只能⽀持⼀个域名。但是随着虚拟主机技术的发展，需要实现在⼀台物理主机上绑定多个虚拟主机，每个虚拟主机都有⾃⼰的单独的域名，这些单独的域名都公⽤同⼀个 IP 地址。

因此，HTTP1.1 的请求头中增加了 Host 字段，⽤来表⽰当前的域名地址，这样服务器就可以根据不同的 Host 值做不同的处理。

4. 对动态⽣成的内容提供了完美⽀持

在设计 HTTP1.0 时，需要在响应头中设置完整的数据⼤⼩，如 Content-Length: 901，这样浏览器就可 以根据设置的数据⼤⼩来接收数据。不过随着服务器端的技术发展，很多⻚⾯的内容都是动态⽣成的，因此 在传输数据之前并不知道最终的数据⼤⼩，这就导致了浏览器不知道何时会接收完所有的⽂件数据。

HTTP1.1 通过引⼊ Chunk transfer 机制来解决这个问题，服务器会将数据分割成若⼲个任意⼤⼩的数据块，每个数据块发送时会附上上个数据块的⻓度，最后使⽤⼀个零⻓度的块作为发送数据完成的标志。这样就提供了对动态内容的⽀持。

5. 客⼾端 Cookie、安全机制

存储一些基本的标识信息来确定每个用户到底是谁，同时同源策略保证用户信息的隔离。

## 即将到来 HTTP2.0

虽然 HTTP1.1 采取了很多优化资源加载速度的策略，也取得了⼀定的效果，但是**HTTP1.1 对带宽的利⽤率却并不理想**，这也是 HTTP1.1 的⼀个核⼼问题。

**带宽是指每秒最⼤能发送或者接收的字节数**。我们把每秒能发送的最⼤字节数称为**上⾏带宽**，每秒能够接收的最⼤字节数称为**下⾏带宽**。

之所以说 HTTP1.1 对带宽的利⽤率不理想，是因为 HTTP1.1 很难将带宽⽤满。⽐如我们常说的 100M 带宽，实际的下载速度能达到 12.5M/S，⽽采⽤ HTTP1.1 时，也许在加载⻚⾯资源时最⼤只能使⽤到 2.5M/S，很难将 12.5M 全部⽤满。

主要原因还是以下几点：

- TCP 慢启动

⼀旦⼀个 TCP 连接建⽴之后，就进⼊了发送数据状态，刚开始 TCP 协议会采⽤⼀个⾮常慢的速度去发送数据，然后慢慢加快发送数据的速度，直到发送数据的速度达到⼀个理想状态，我们把这个过程称为慢启动。

可以把每个 TCP 发送数据的过程看成是⼀辆⻋的启动过程，当刚进⼊公路时，会有从 0 到⼀个稳定速度的提速过程，TCP 的慢启动就类似于该过程。

慢启动是 TCP 为了减少⽹络拥塞的⼀种策略，我们是没有办法改变的。⽽之所以说慢启动会带来性能问题，是因为⻚⾯中常⽤的⼀些关键资源⽂件本来就不⼤，如 HTML ⽂件、CSS ⽂件和 JavaScript ⽂件，通常这些⽂件在 TCP 连接建⽴好之后就要发起请求的，但这个过程是慢启动，
所以耗费的时间⽐正常的时间要多很多，这样就推迟了宝贵的⾸次渲染⻚⾯的时⻓了。

- 同时开启了多条 TCP 连接，那么这些连接会竞争固定的带宽

系统同时建⽴了多条 TCP 连接，当带宽充⾜时，每条连接发送或者接收速度会慢慢向上增 加；⽽⼀旦带宽不⾜时，这些 TCP 连接⼜会减慢发送或者接收的速度。⽐如⼀个⻚⾯有 200 个⽂件，使⽤了 3 个 CDN，那么加载该⽹⻚的时候就需要建⽴ 6 \* 3，也就是 18 个 TCP 连接来下载资源；在下载过程中，当发现 带宽不⾜的时候，各个 TCP 连接就需要动态减慢接收数据的速度。

这样就会出现⼀个问题，因为有的 TCP 连接下载的是⼀些关键资源，如 CSS ⽂件、JavaScript ⽂件等，⽽有的 TCP 连接下载的是图⽚、视频等普通的资源⽂件，但是多条 TCP 连接之间⼜不能协商让哪些关键资源优先下载，这样就有可能影响那些关键资源的下载速度了。

- HTTP1.1 队头阻塞的问题

在 HTTP1.1 中使⽤持久连接时，虽然能公⽤⼀个 TCP 管道，但是在⼀个管道中同⼀时刻只能处理⼀个请求，在当前的请求没有结束之前，其他的请求只能处于阻塞状态。这意味着我们不能随意在⼀个管道中发送请求和接收内容。

因为阻塞请求的因素有很多，并且都是⼀些不确定性的因素，假如有的请求被阻塞了 5 秒，那么后续排队的请求都要延迟等待 5 秒，在这个等待的过程中，带宽、CPU 都被⽩⽩浪费了。

在浏览器处理⽣成⻚⾯的过程中，是⾮常希望能提前接收到数据的，这样就可以对这些数据做预处理操作，⽐如提前接收到了图⽚，那么就可以提前进⾏编解码操作，等到需要使⽤该图⽚的时候，就可以直接给出处理后的数据了，这样能让⽤⼾感受到整体速度的提升。

但队头阻塞使得这些数据不能并⾏请求，所以队头阻塞是很不利于浏览器优化的。

### HTTP2.0 的多路复⽤

虽然 TCP 有问题，但是我们依然没有换掉 TCP 的能⼒，所以我们就要想办法去规避 TCP 的慢启动和 TCP 连接之间的竞争问题。

基于此，HTTP2.0 的思路就是⼀个域名只使⽤⼀个 TCP ⻓连接来传输数据，这样整个⻚⾯资源的下载过程只需要⼀次慢启动，同时也避免了多个 TCP 连接竞争带宽所带来的问题。

另外，就是队头阻塞的问题，等待请求完成后才能去请求下⼀个资源，这种⽅式⽆疑是最慢的，所以 HTTP2.0 需要实现资源的并⾏请求，也就是任何时候都可以将请求发送给服务器，⽽并不需要等待其他请求的完成，然后服务器也可以随时返回处理好的请求资源给浏览器。

所以，HTTP2.0 的解决⽅案可以总结为：⼀个域名只使⽤⼀个 TCP ⻓连接和消除队头阻塞问题。如下图：

<img :src="$withBase('/image/HTTP2.0的多路复⽤.png')" alt="HTTP2.0的多路复⽤" />

现每个请求都有⼀个对应的 ID，如 stream1 表⽰ index.html 的请求，stream2 表⽰ foo.css 的请求。这样在浏览器端，就可以随时将请求发送给服务器了。

服务器端接收到这些请求后，会根据⾃⼰的喜好来决定优先返回哪些内容，⽐如服务器可能早就缓存好了 index.html 和 bar.js 的响应头信息，那么当接收到请求的时候就可以⽴即把 index.html 和 bar.js 的响应头信息返回给浏览器，然后再将 index.html 和 bar.js 的响应体数据返回给浏览器。之所以可以随意发送，是因为每份数据都有对应的 ID，浏览器接收到之后，会筛选出相同 ID 的内容，将其拼接为完整的 HTTP 响应数据。

HTTP2.0 使⽤了多路复⽤技术，可以将请求分成⼀帧⼀帧的数据去传输，这样带来了⼀个额外的好处，就是当收到⼀个优先级⾼的请求时，⽐如接收到 JavaScript 或者 CSS 关键资源的请求，服务器可以暂停之前的请求来优先处理关键资源的请求。

### 多路复⽤的实现

<img :src="$withBase('/image/HTTP2.0协议栈.png')" alt="HTTP2.0协议栈" height="300"/>

从图中可以看出，HTTP2.0 添加了**⼀个⼆进制分帧层**，那我们就结合图来分析下 HTTP2.0 的请求和接收过程。

- ⾸先，浏览器准备好请求数据，包括了请求⾏、请求头等信息，如果是 POST ⽅法，那么还要有请求体。
- 这些数据经过⼆进制分帧层处理之后，会被转换为⼀个个带有请求 ID 编号的帧，通过协议栈将这些帧发送给服务器。
- 服务器接收到所有帧之后，会将所有相同 ID 的帧合并为⼀条完整的请求信息。
- 然后服务器处理该条请求，并将处理的响应⾏、响应头和响应体分别发送⾄⼆进制分帧层。
- 同样，⼆进制分帧层会将这些响应数据转换为⼀个个带有请求 ID 编号的帧，经过协议栈发送给浏览器。
- 浏览器接收到响应帧之后，会根据 ID 编号将帧的数据提交给对应的请求。

### 其他特性

多路复⽤是 HTTP2.0 的最核⼼功能，它能实现资源的并⾏传输。多路复⽤技术是建⽴在⼆进制分帧层的基础之上。其实基于⼆进制分帧层，HTTP2.0 还附带实现了很多其他功能:

1. 设置请求的优先级

浏览器中有些数据是⾮常重要的，但是在发送请求时，重要的请求可能会晚于那些不怎么重要的请
求，如果服务器按照请求的顺序来回复数据，那么这个重要的数据就有可能推迟很久才能送达浏览器，这对于⽤⼾体验来说是⾮常不友好的。

为了解决这个问题，HTTP2.0 提供了请求优先级，可以在发送请求时，标上该请求的优先级，这样服务器接收到请求之后，会优先处理优先级⾼的请求。

2. 服务器推送

除了设置请求的优先级外，HTTP2.0 还可以直接将数据提前推送到浏览器。可以想象这样⼀个场景，当⽤⼾请求⼀个 HTML ⻚⾯之后，服务器知道该 HTML ⻚⾯会引⽤⼏个重要的 JavaScript ⽂件和 CSS ⽂件，那么在接收到 HTML 请求之后，附带将要使⽤的 CSS ⽂件和 JavaScript ⽂件⼀并发送给浏览器，这样当浏览器解析完 HTML ⽂件之后，就能直接拿到需要的 CSS ⽂件和 JavaScript ⽂件，这对⾸次打开⻚⾯的速度起到了⾄关重要的作⽤。

3. 头部压缩

⽆论是 HTTP1.1 还是 HTTP2.0，它们都有请求头和响应头，这是浏览器和服务器的通信语⾔。HTTP2.0 对请求头和响应头进⾏了压缩，可能觉得⼀个 HTTP 的头⽂件没有多⼤，压不压缩可能关系不⼤，但这样想⼀下，在浏览器发送请求的时候，基本上都是发送 HTTP 请求头，很少有请求体的发送，通常情况下⻚⾯也有 100 个左右的资源，如果将这 100 个请求头的数据压缩为原来的 20%，那么传输效率肯定能得到⼤幅提升。

## HTTP3.0

其实 2.0 版本似乎已经很完美了，为什么还要出 3.0 呢？ 虽然 HTTP2.0 解决了应⽤层⾯的队头阻塞问题，不过和 HTTP/1.1 ⼀样，HTTP2.0 依然是基于 TCP 协议的，⽽ TCP 最初就是为了单连接⽽设计的。可以把 TCP 连接看成是两台计算机之前的⼀个虚拟管道，计算机的⼀端将要传输的数据按照顺序放⼊管道，最终数据会以相同的顺序出现在管道的另外⼀头。

<img :src="$withBase('/image/正常TCP传输数据过程.png')" alt="正常TCP传输数据过程"/>

从⼀端发送给另外⼀端的数据会被拆分为⼀个个按照顺序排列的数据包，这些数据包通过⽹络传输到了接收端，接收端再按照顺序将这些数据包组合成原始数据，这样就完成了数据传输。

不过，如果在数据传输的过程中，有⼀个数据因为⽹络故障或者其他原因⽽丢包了，那么整个 TCP 的连接就会处于暂停状态，需要等待丢失的数据包被重新传输过来。可以把 TCP 连接看成是⼀个按照顺序传输数据的管道，管道中的任意⼀个数据丢失了，那之后的数据都需要等待该数据的重新传输。为了直观理解，可以参考下图：

<img :src="$withBase('/image/TCP丢包状态.png')" alt="TCP丢包状态"/>

在 TCP 传输过程中，由于单个数据包的丢失⽽造成的阻塞称为**TCP 上的队头阻塞**。

队头阻塞是怎么影响 HTTP2.0 传输的呢？⾸先我们来看正常情况下 HTTP2.0 是怎么传输多路请求的，为了直
观理解，可以参考下图：
<img :src="$withBase('/image/HTTP2.0多路复⽤示意图.png')" alt="HTTP2.0多路复⽤示意图"/>

通过该图，我们知道在 HTTP2.0 中，多个请求是跑在⼀个 TCP 管道中的，如果其中任意⼀路数据流中出现了丢包的情况，那么就会阻塞该 TCP 连接中的所有请求。这不同于 HTTP/1.1，使⽤ HTTP/1.1 时，浏览器为每个域名开启了 6 个 TCP 连接，如果其中的 1 个 TCP 连接发⽣了队头阻塞，那么其他的 5 个连接依然可以继续传输数据。

所以随着丢包率的增加，HTTP2.0 的传输效率也会越来越差。有测试数据表明，当系统达到了 2%的丢包率时，HTTP/1.1 的传输效率反⽽⽐ HTTP2.0 表现得更好。

### TCP 建⽴连接的延时

除了 TCP 队头阻塞之外，TCP 的握⼿过程也是影响传输效率的⼀个重要因素。

为了搞清楚 TCP 协议建⽴连接的延迟问题，我们还是先来回顾下⽹络延迟的概念，这会有助于对后⾯内容 的理解。⽹络延迟⼜称为 RTT（Round Trip Time）。我们把从浏览器发送⼀个数据包到服务器，再从服务 器返回数据包到浏览器的整个往返时间称为 RTT（如下图）。RTT 是反映⽹络性能的⼀个重要指标。

<img :src="$withBase('/image/⽹络延时.png')" alt="⽹络延时"/>

那建⽴ TCP 连接时，需要花费多少个 RTT 呢？

HTTP1.1 和 HTTP2.0 都是使⽤ TCP 协议来传输的，⽽如果使⽤ HTTPS 的话，还需要使⽤ TLS 协议进⾏
安全传输，⽽使⽤ TLS 也需要⼀个握⼿过程，这样就需要有两个握⼿延迟过程。

1. 在建⽴ TCP 连接的时候，需要和服务器进⾏三次握⼿来确认连接成功，也就是说需要在消耗完 1.5 个 RTT 之后才能进⾏数据传输。
2. 进⾏ TLS 连接，TLS 有两个版本⸺TLS1.2 和 TLS1.3，每个版本建⽴连接所花的时间不同，⼤致是需要 1〜2 个 RTT，关于 HTTPS 我们到后⾯到安全模块再做详细介绍。

总之，在传输数据之前，我们需要花掉 3〜4 个 RTT。如果浏览器和服务器的物理距离较近，那么 1 个 RTT 的时间可能在 10 毫秒以内，也就是说总共要消耗掉 30〜40 毫秒。这个时间也许⽤⼾还可以接受，但如果服务器相隔较远，那么 1 个 RTT 就可能需要 100 毫秒以上了，这种情况下整个握⼿过程需要 300〜400 毫秒，这时⽤⼾就能明显地感受到“慢”了。

### TCP 协议僵化

既然 TCP 协议存在队头阻塞和建⽴连接延迟等缺点，那我们是不是可以通过改进 TCP 协议来解决
这些问题呢？

**几乎不行**

第⼀个是中间设备的僵化。要搞清楚什么是中间设备僵化，我们先要弄明⽩什么是中间设备。我们知道互联⽹是由多个⽹络互联的⽹状结构，为了能够保障互联⽹的正常⼯作，我们需要在互联⽹的各处搭建路由器、防⽕墙、NAT、交换机等各种设备，这些设备就被称为中间设备。

如果我们在客⼾端升级了 TCP 协议，但是当新协议的数据包经过这些没有更新的中间设备时，它们可能不理解包
的内容，于是这些数据就会被丢弃掉。这就是中间设备僵化，它是阻碍 TCP 更新的⼀⼤障碍。

除了中间设备僵化外，**操作系统也是导致 TCP 协议僵化的另外⼀个原因**。因为 TCP 协议都是通过操作系统内核来实现的，应⽤程序只能使⽤不能修改。通常操作系统的更新都滞后于软件的更新，因此要想⾃由地更新内核中的 TCP 协议也是⾮常困难的。

### QUIC 协议

HTTP2.0 存在⼀些⽐较严重的与 TCP 协议相关的缺陷，但由于 TCP 协议僵化，我们⼏乎不可能通过修改 TCP 协议⾃⾝来解决这些问题，那么解决问题的思路是绕过 TCP 协议，发明⼀个 TCP 和 UDP 之外的新的传输协议。但是这也⾯临着和修改 TCP ⼀样的挑战，因为中间设备的僵化，这些设备只认 TCP 和 UDP，如果采⽤了新的协议，新协议在这些设备同样不被很好地⽀持。

因此，HTTP3.0 选择了⼀个折衷的⽅法⸺UDP 协议，基于 UDP 实现了类似于 TCP 的多路数据流、传输可靠性等功能，我们把这套功能称为 QUIC 协议。关于 HTTP2.0 和 HTTP3.0 协议栈的⽐较，可以参考下图：
<img :src="$withBase('/image/HTTP2和HTTP3协议栈.png')" alt="HTTP2和HTTP3协议栈" height="300"/>

HTTP/3 中的 QUIC 协议集合了以下⼏点功能:

- 实现了类似 TCP 的流量控制、传输可靠性的功能。虽然 UDP 不提供可靠性的传输，但 QUIC 在 UDP 的基础之上增加了⼀层来保证数据可靠性传输。它提供了数据包重传、拥塞控制以及其他⼀些 TCP 中存在的特性。
- 集成了 TLS 加密功能。⽬前 QUIC 使⽤的是 TLS1.3，相较于早期版本 TLS1.3 有更多的优点，其中最重要的⼀点是减少了握⼿所花费的 RTT 个数。
- 实现了 HTTP/2 中的多路复⽤功能。和 TCP 不同，QUIC 实现了在同⼀物理连接上可以有多个独⽴的逻辑数据流（如下图）。实现了数据流的单独传输，就解决了 TCP 中队头阻塞的问题。

<img :src="$withBase('/image/QUIC协议的多路复⽤.png')" alt="QUIC协议的多路复⽤"/>

- 实现了快速握⼿功能。由于 QUIC 是基于 UDP 的，所以 QUIC 可以实现使⽤ 0-RTT 或者 1-RTT 来建⽴连接，这意味着 QUIC 可以⽤最快的速度来发送和接收数据，这样可以⼤⼤提升⾸次打开⻚⾯的速度。

### 艰难之路

通过上⾯的分析，我们相信在技术层⾯，HTTP/3 是个完美的协议。不过要将 HTTP/3 应⽤到实际环境中依然⾯临着诸多严峻的挑战，这些挑战主要来⾃于以下三个⽅⾯。

- 第⼀，从⽬前的情况来看，服务器和浏览器端都没有对 HTTP/3 提供⽐较完整的⽀持。Chrome 虽然在数年前就开始⽀持 Google 版本的 QUIC，但是这个版本的 QUIC 和官⽅的 QUIC 存在着⾮常⼤的差异。

- 第⼆，部署 HTTP/3 也存在着⾮常⼤的问题。因为系统内核对 UDP 的优化远远没有达到 TCP 的优化程度，这也是阻碍 QUIC 的⼀个重要原因。

- 第三，中间设备僵化的问题。这些设备对 UDP 的优化程度远远低于 TCP，据统计使⽤ QUIC 协议时，⼤约有 3%〜7%的丢包率。
