---
title: 26.HTTP各个版本
date: 2020-05-29
---

## 前言
浏览器中的⽹络，就避不开HTTP。绝大部分前端工程师知道HTTP是浏览器中最重要且使⽤最多的协议，是浏览器和服务器之间的通信语⾔，也是互联⽹的基⽯。⽽随着浏览器的发展，HTTP为了能适应新的形式也在持续进化，但在开发过程中不会特别在意HTTP版本问题，而且绝大多数的网站使用的都是HTTP1.1的版本内容，因为业务复杂度不高，对这些没有需求，但随着前后端的迅速发展，前后端的通信也越来越多，前端需要的数据也越来越多，网络成了制约前端获取数据性能的一大问题，那么什么样的版本会给现有项目带来更高性能的体验呢？我们需要对各个版本的HTTP有一定的了解，才能正确选择，为项目优化添砖加瓦。


## HTTP 1.0

⾸先我们来看看诞⽣最早的HTTP0.9。HTTP0.9是于1991年提出的，主要⽤于学术交流，需求很简单⸺⽤来在⽹络之间**传递HTML超⽂本的内容**，所以被称为超⽂本传输协议。整体来看，它的实现也很简单，采⽤了基于请求响应的模式，从客⼾端发出请求，服务器返回数据。

<img :src="$withBase('/image/HTTP0.9.png')" alt="HTTP0.9" />

+ 因为HTTP都是基于TCP协议的，所以客⼾端先要根据IP地址、端⼝和服务器建⽴TCP连接，⽽建⽴连接的过程就是TCP协议三次握⼿的过程。
+ 建⽴好连接之后，会发送⼀个GET请求⾏的信息，如GET /index.html⽤来获取index.html。
+ 服务器接收请求信息之后，读取对应的HTML⽂件，并将数据以ASCII字符流返回给客⼾端。HTML⽂档传输完成后，断开连接。

而随后的几年里HTTP/0.9已经不能适⽤新兴⽹络的发展，所以这时就需要⼀个新的协议来⽀撑新兴⽹络，这就是HTTP1.0诞⽣的原因。⾸先在浏览器中展⽰的不单是HTML⽂件了，还包括了**JavaScript、CSS、图⽚、⾳频、视频等不同类型的⽂件**。因此⽀持多种类型的⽂件下载是HTTP1.0的⼀个核⼼诉求，⽽且⽂件格式不仅仅局限于ASCII编码，还有很多其他类型编码的⽂件。

**该如何实现多种类型⽂件的下载呢？**

HTTP是浏览器和服务器之间的通信语⾔，不过HTTP/0.9在建⽴好连接之后，只会发送
类似GET /index.html的简单请求命令，并没有其他途径告诉服务器更多的信息，如⽂件编码、⽂件类型等。同样，服务器是直接返回数据给浏览器的，也没有其他途径告诉浏览器更多的关于服务器返回的⽂件信息。

这种简单的交流型形式⽆疑不能满⾜传输多种类型⽂件的需求，那为了让客⼾端和服务器能更深⼊地交流，HTTP1.0引⼊了请求头和响应头，它们都是以为Key-Value形式保存的，在HTTP发送请求时，会带上请求头信息，服务器返回数据时，会先返回响应头信息。⾄于HTTP1.0具体的请求流程，可以参考下图。

<img :src="$withBase('/image/HTTP1.0.png')" alt="HTTP1.0" />

为了支持不同的数据类型，HTTP1.0是通过设置请求头和响应头来确定。

+ ⾸先，浏览器需要知道服务器返回的数据是什么类型的，然后浏览器才能根据不同的数据类型做针对性的处理。
+ 其次，由于万维⽹所⽀持的应⽤变得越来越⼴，所以单个⽂件的数据量也变得越来越⼤。为了减轻传输性能，服务器会对数据进⾏压缩后再传输，所以浏览器需要知道服务器压缩的⽅法。
+ 再次，由于万维⽹是⽀持全球范围的，所以需要提供国际化的⽀持，服务器需要对不同的地区提供不同的语⾔版本，这就需要浏览器告诉服务器它想要什么语⾔版本的⻚⾯。

+ 最后，由于增加了各种不同类型的⽂件，⽽每种⽂件的编码形式⼜可能不⼀样，为了能够准确地读取⽂件，浏览器需要知道⽂件的编码类型。

基于以上问题，HTTP1.0的⽅案是通过请求头和响应头来进⾏协商，在发起请求时候会通过HTTP请求头告诉服务器它期待服务器返回什么类型的⽂件、采取什么形式的压缩、提供什么语⾔的⽂件以及⽂件的具体编码。最终发送出来的请求头内容如下：

```js
accept: text/html
accept-encoding: gzip, deflate, br
accept-Charset: ISO-8859-1,utf-8
accept-language: zh-CN,zh
```

其中第⼀⾏表⽰期望服务器返回html类型的⽂件，第⼆⾏表⽰期望服务器可以采⽤gzip、deflate或者br其中的⼀种压缩⽅式，第三⾏表⽰期望返回的⽂件编码是UTF-8或者ISO-8859-1，第四⾏是表⽰期望⻚⾯的优先语⾔是中⽂。

服务器接收到浏览器发送过来的请求头信息之后，会根据请求头的信息来准备响应数据。不过有时候会有⼀些意外情况发⽣，⽐如浏览器请求的压缩类型是gzip，但是服务器不⽀持gzip，只⽀持br压缩，那么它会通过响应头中的content-encoding字段告诉浏览器最终的压缩类型，也就是说最终浏览器需要根据响应头的信息来处理数据。下⾯是⼀段响应头的数据信息：

```js
content-encoding: br
content-type: text/html; charset=UTF-8
```

其中第⼀⾏表⽰服务器采⽤了br的压缩⽅法，第⼆⾏表⽰服务器返回的是html⽂件，并且该⽂件的编码类型是UTF-8。

有了响应头的信息，浏览器就会使⽤br⽅法来解压⽂件，再按照UTF-8的编码格式来处理原始⽂件，最后按照HTML的⽅式来解析该⽂件。这就是HTTP1.0⽀持多⽂件的⼀个基本的处理流程。

HTTP1.0除了对多⽂件提供良好的⽀持外，还依据当时实际的需求引⼊了很多其他的特性，这些特性都是通过请求头和响应头来实现的。下⾯我们来看看新增的⼏个典型的特性：

+ 有的请求服务器可能⽆法处理，或者处理出错，这时候就需要告诉浏览器服务器最终处理该请求的情况，这就引⼊了***状态码*。状态码是通过响应⾏的⽅式来通知浏览器的。

+ 为了减轻服务器的压⼒，在HTTP1.0中提供了**Cache机制**，⽤来缓存已经下载过的数据.

+ 服务器需要统计客⼾端的基础信息，⽐如Windows和macOS的⽤⼾数量分别是多少，所以HTTP1.0的请求头中还加⼊了**⽤⼾代理的字段**。

## HTTP1.1: 1.0的增强版

我们看一下增强了什么：

1. 改进持久连接

HTTP1.0每进⾏⼀次HTTP通信，都需要经历建⽴TCP连接、传输HTTP数据和断开TCP连接三个阶段。

<img :src="$withBase('/image/HTTP1.0短连接.png')" alt="HTTP1.0短连接" height="300"/>

在当时，由于通信的⽂件⽐较⼩，⽽且每个⻚⾯的引⽤也不多，所以这种传输形式没什么⼤问题。但是随着浏览器普及，单个⻚⾯中的图⽚⽂件越来越多，有时候⼀个⻚⾯可能包含了⼏百个外部引⽤的资源⽂件，如果在下载每个⽂件的时候，都需要经历建⽴TCP连接、传输数据和断开连接这样的步骤，⽆疑会增加⼤量⽆谓的开销。

为了解决这个问题，HTTP1.1中通过设置`Connection: keep-alive `增加了长连接的⽅法，它的特点是在⼀个TCP连接上可以传输多个HTTP请求，只要浏览器或者服务器没有明确断开连接，那么该TCP连接会⼀直保持

<img :src="$withBase('/image/HTTP1.1长连接.png')" alt="HTTP1.1长连接" height="300"/>

持久连接在HTTP1.1中是默认开启的，所以不需要专⻔为了持久连接去HTTP请求头设置信息，如果不想要采⽤持久连接，可以在HTTP请求头中加上`Connection: close `。⽬前浏览器中对于同⼀个域名，默认允许同时建⽴6个TCP持久连接。

2. 不怎么使用的HTTP管线化

持久连接虽然能减少TCP的建⽴和断开次数，但是它需要等待前⾯的请求返回之后，才能进⾏下⼀次请求。如果TCP通道中的某个请求因为某些原因没有及时返回，那么就会阻塞后⾯的所有请求，这就是著名的**队头阻塞**的问题。

HTTP1.1中试图通过管线化的技术来解决队头阻塞的问题。HTTP1.1中的管线化是指将多个HTTP请求整批提交给服务器的技术，虽然可以整批发送请求，不过服务器依然需要根据请求顺序来回复浏览器的请求。

但是不同的浏览器在管线化技术上有不同的差异，导致我们在开发过程中很少使用它。

3. 提供虚拟主机的⽀持

在HTTP1.0中，每个域名绑定了⼀个唯⼀的IP地址，因此⼀个服务器只能⽀持⼀个域名。但是随着虚拟主机技术的发展，需要实现在⼀台物理主机上绑定多个虚拟主机，每个虚拟主机都有⾃⼰的单独的域名，这些单独的域名都公⽤同⼀个IP地址。

因此，HTTP1.1的请求头中增加了Host字段，⽤来表⽰当前的域名地址，这样服务器就可以根据不同的Host值做不同的处理。

4. 对动态⽣成的内容提供了完美⽀持

在设计HTTP1.0时，需要在响应头中设置完整的数据⼤⼩，如Content-Length: 901，这样浏览器就可 以根据设置的数据⼤⼩来接收数据。不过随着服务器端的技术发展，很多⻚⾯的内容都是动态⽣成的，因此 在传输数据之前并不知道最终的数据⼤⼩，这就导致了浏览器不知道何时会接收完所有的⽂件数据。

HTTP1.1通过引⼊Chunk transfer机制来解决这个问题，服务器会将数据分割成若⼲个任意⼤⼩的数据块，每个数据块发送时会附上上个数据块的⻓度，最后使⽤⼀个零⻓度的块作为发送数据完成的标志。这样就提供了对动态内容的⽀持。

5. 客⼾端Cookie、安全机制

存储一些基本的标识信息来确定每个用户到底是谁，同时同源策略保证用户信息的隔离。

## 即将到来HTTP2.0

虽然HTTP1.1采取了很多优化资源加载速度的策略，也取得了⼀定的效果，但是**HTTP1.1对带宽的利⽤率却并不理想**，这也是HTTP1.1的⼀个核⼼问题。

**带宽是指每秒最⼤能发送或者接收的字节数**。我们把每秒能发送的最⼤字节数称为**上⾏带宽**，每秒能够接收的最⼤字节数称为**下⾏带宽**。

之所以说HTTP1.1对带宽的利⽤率不理想，是因为HTTP1.1很难将带宽⽤满。⽐如我们常说的100M带宽，实际的下载速度能达到12.5M/S，⽽采⽤HTTP1.1时，也许在加载⻚⾯资源时最⼤只能使⽤到2.5M/S，很难将12.5M全部⽤满。

主要原因还是以下几点：
+ TCP慢启动

⼀旦⼀个TCP连接建⽴之后，就进⼊了发送数据状态，刚开始TCP协议会采⽤⼀个⾮常慢的速度去发送数据，然后慢慢加快发送数据的速度，直到发送数据的速度达到⼀个理想状态，我们把这个过程称为慢启动。

可以把每个TCP发送数据的过程看成是⼀辆⻋的启动过程，当刚进⼊公路时，会有从0到⼀个稳定速度的提速过程，TCP的慢启动就类似于该过程。

慢启动是TCP为了减少⽹络拥塞的⼀种策略，我们是没有办法改变的。⽽之所以说慢启动会带来性能问题，是因为⻚⾯中常⽤的⼀些关键资源⽂件本来就不⼤，如HTML⽂件、CSS⽂件和JavaScript⽂件，通常这些⽂件在TCP连接建⽴好之后就要发起请求的，但这个过程是慢启动，
所以耗费的时间⽐正常的时间要多很多，这样就推迟了宝贵的⾸次渲染⻚⾯的时⻓了。

+ 同时开启了多条TCP连接，那么这些连接会竞争固定的带宽

系统同时建⽴了多条TCP连接，当带宽充⾜时，每条连接发送或者接收速度会慢慢向上增 加；⽽⼀旦带宽不⾜时，这些TCP连接⼜会减慢发送或者接收的速度。⽐如⼀个⻚⾯有200个⽂件，使⽤了3 个CDN，那么加载该⽹⻚的时候就需要建⽴6 * 3，也就是18个TCP连接来下载资源；在下载过程中，当发现 带宽不⾜的时候，各个TCP连接就需要动态减慢接收数据的速度。

这样就会出现⼀个问题，因为有的TCP连接下载的是⼀些关键资源，如CSS⽂件、JavaScript⽂件等，⽽有的TCP连接下载的是图⽚、视频等普通的资源⽂件，但是多条TCP连接之间⼜不能协商让哪些关键资源优先下载，这样就有可能影响那些关键资源的下载速度了。

+ HTTP1.1队头阻塞的问题

在HTTP1.1中使⽤持久连接时，虽然能公⽤⼀个TCP管道，但是在⼀个管道中同⼀时刻只能处理⼀个请求，在当前的请求没有结束之前，其他的请求只能处于阻塞状态。这意味着我们不能随意在⼀个管道中发送请求和接收内容。

因为阻塞请求的因素有很多，并且都是⼀些不确定性的因素，假如有的请求被阻塞了5秒，那么后续排队的请求都要延迟等待5秒，在这个等待的过程中，带宽、CPU都被⽩⽩浪费了。

在浏览器处理⽣成⻚⾯的过程中，是⾮常希望能提前接收到数据的，这样就可以对这些数据做预处理操作，⽐如提前接收到了图⽚，那么就可以提前进⾏编解码操作，等到需要使⽤该图⽚的时候，就可以直接给出处理后的数据了，这样能让⽤⼾感受到整体速度的提升。

但队头阻塞使得这些数据不能并⾏请求，所以队头阻塞是很不利于浏览器优化的。

### HTTP2.0的多路复⽤

虽然TCP有问题，但是我们依然没有换掉TCP的能⼒，所以我们就要想办法去规避TCP的慢启动和TCP连接之间的竞争问题。

基于此，HTTP2.0的思路就是⼀个域名只使⽤⼀个TCP⻓连接来传输数据，这样整个⻚⾯资源的下载过程只需要⼀次慢启动，同时也避免了多个TCP连接竞争带宽所带来的问题。

另外，就是队头阻塞的问题，等待请求完成后才能去请求下⼀个资源，这种⽅式⽆疑是最慢的，所以HTTP2.0需要实现资源的并⾏请求，也就是任何时候都可以将请求发送给服务器，⽽并不需要等待其他请求的完成，然后服务器也可以随时返回处理好的请求资源给浏览器。

所以，HTTP2.0的解决⽅案可以总结为：⼀个域名只使⽤⼀个TCP⻓连接和消除队头阻塞问题。如下图：

<img :src="$withBase('/image/HTTP2.0的多路复⽤.png')" alt="HTTP2.0的多路复⽤" />

现每个请求都有⼀个对应的ID，如stream1表⽰index.html的请求，stream2表⽰foo.css的请求。这样在浏览器端，就可以随时将请求发送给服务器了。

服务器端接收到这些请求后，会根据⾃⼰的喜好来决定优先返回哪些内容，⽐如服务器可能早就缓存好了index.html和bar.js的响应头信息，那么当接收到请求的时候就可以⽴即把index.html和bar.js的响应头信息返回给浏览器，然后再将index.html和bar.js的响应体数据返回给浏览器。之所以可以随意发送，是因为每份数据都有对应的ID，浏览器接收到之后，会筛选出相同ID的内容，将其拼接为完整的HTTP响应数据。

HTTP2.0使⽤了多路复⽤技术，可以将请求分成⼀帧⼀帧的数据去传输，这样带来了⼀个额外的好处，就是当收到⼀个优先级⾼的请求时，⽐如接收到JavaScript或者CSS关键资源的请求，服务器可以暂停之前的请求来优先处理关键资源的请求。

### 多路复⽤的实现

<img :src="$withBase('/image/HTTP2.0协议栈.png')" alt="HTTP2.0协议栈" height="300"/>

从图中可以看出，HTTP2.0添加了**⼀个⼆进制分帧层**，那我们就结合图来分析下HTTP2.0的请求和接收过程。

+ ⾸先，浏览器准备好请求数据，包括了请求⾏、请求头等信息，如果是POST⽅法，那么还要有请求体。
+ 这些数据经过⼆进制分帧层处理之后，会被转换为⼀个个带有请求ID编号的帧，通过协议栈将这些帧发送给服务器。
+ 服务器接收到所有帧之后，会将所有相同ID的帧合并为⼀条完整的请求信息。
+ 然后服务器处理该条请求，并将处理的响应⾏、响应头和响应体分别发送⾄⼆进制分帧层。
+ 同样，⼆进制分帧层会将这些响应数据转换为⼀个个带有请求ID编号的帧，经过协议栈发送给浏览器。
+ 浏览器接收到响应帧之后，会根据ID编号将帧的数据提交给对应的请求。

### 其他特性

多路复⽤是HTTP2.0的最核⼼功能，它能实现资源的并⾏传输。多路复⽤技术是建⽴在⼆进制分帧层的基础之上。其实基于⼆进制分帧层，HTTP2.0还附带实现了很多其他功能:

1. 设置请求的优先级

浏览器中有些数据是⾮常重要的，但是在发送请求时，重要的请求可能会晚于那些不怎么重要的请
求，如果服务器按照请求的顺序来回复数据，那么这个重要的数据就有可能推迟很久才能送达浏览器，这对于⽤⼾体验来说是⾮常不友好的。

为了解决这个问题，HTTP2.0提供了请求优先级，可以在发送请求时，标上该请求的优先级，这样服务器接收到请求之后，会优先处理优先级⾼的请求。

2. 服务器推送

除了设置请求的优先级外，HTTP2.0还可以直接将数据提前推送到浏览器。可以想象这样⼀个场景，当⽤⼾请求⼀个HTML⻚⾯之后，服务器知道该HTML⻚⾯会引⽤⼏个重要的JavaScript⽂件和CSS⽂件，那么在接收到HTML请求之后，附带将要使⽤的CSS⽂件和JavaScript⽂件⼀并发送给浏览器，这样当浏览器解析完HTML⽂件之后，就能直接拿到需要的CSS⽂件和JavaScript⽂件，这对⾸次打开⻚⾯的速度起到了⾄关重要的作⽤。

3. 头部压缩

⽆论是HTTP1.1还是HTTP2.0，它们都有请求头和响应头，这是浏览器和服务器的通信语⾔。HTTP2.0对请求头和响应头进⾏了压缩，可能觉得⼀个HTTP的头⽂件没有多⼤，压不压缩可能关系不⼤，但这样想⼀下，在浏览器发送请求的时候，基本上都是发送HTTP请求头，很少有请求体的发送，通常情况下⻚⾯也有100个左右的资源，如果将这100个请求头的数据压缩为原来的20%，那么传输效率肯定能得到⼤幅提升。

## HTTP3.0

其实2.0版本似乎已经很完美了，为什么还要出3.0呢？ 虽然HTTP2.0解决了应⽤层⾯的队头阻塞问题，不过和HTTP/1.1⼀样，HTTP2.0依然是基于TCP协议的，⽽TCP最初就是为了单连接⽽设计的。可以把TCP连接看成是两台计算机之前的⼀个虚拟管道，计算机的⼀端将要传输的数据按照顺序放⼊管道，最终数据会以相同的顺序出现在管道的另外⼀头。

<img :src="$withBase('/image/正常TCP传输数据过程.png')" alt="正常TCP传输数据过程"/>

从⼀端发送给另外⼀端的数据会被拆分为⼀个个按照顺序排列的数据包，这些数据包通过⽹络传输到了接收端，接收端再按照顺序将这些数据包组合成原始数据，这样就完成了数据传输。

不过，如果在数据传输的过程中，有⼀个数据因为⽹络故障或者其他原因⽽丢包了，那么整个TCP的连接就会处于暂停状态，需要等待丢失的数据包被重新传输过来。可以把TCP连接看成是⼀个按照顺序传输数据的管道，管道中的任意⼀个数据丢失了，那之后的数据都需要等待该数据的重新传输。为了直观理解，可以参考下图：

<img :src="$withBase('/image/TCP丢包状态.png')" alt="TCP丢包状态"/>

在TCP传输过程中，由于单个数据包的丢失⽽造成的阻塞称为**TCP上的队头阻塞**。

队头阻塞是怎么影响HTTP2.0传输的呢？⾸先我们来看正常情况下HTTP2.0是怎么传输多路请求的，为了直
观理解，可以参考下图：
<img :src="$withBase('/image/HTTP2.0多路复⽤示意图.png')" alt="HTTP2.0多路复⽤示意图"/>

通过该图，我们知道在HTTP2.0中，多个请求是跑在⼀个TCP管道中的，如果其中任意⼀路数据流中出现了丢包的情况，那么就会阻塞该TCP连接中的所有请求。这不同于HTTP/1.1，使⽤HTTP/1.1时，浏览器为每个域名开启了6个TCP连接，如果其中的1个TCP连接发⽣了队头阻塞，那么其他的5个连接依然可以继续传输数据。

所以随着丢包率的增加，HTTP2.0的传输效率也会越来越差。有测试数据表明，当系统达到了2%的丢包率时，HTTP/1.1的传输效率反⽽⽐HTTP2.0表现得更好。

### TCP建⽴连接的延时

除了TCP队头阻塞之外，TCP的握⼿过程也是影响传输效率的⼀个重要因素。

为了搞清楚TCP协议建⽴连接的延迟问题，我们还是先来回顾下⽹络延迟的概念，这会有助于对后⾯内容 的理解。⽹络延迟⼜称为RTT（Round Trip Time）。我们把从浏览器发送⼀个数据包到服务器，再从服务 器返回数据包到浏览器的整个往返时间称为RTT（如下图）。RTT是反映⽹络性能的⼀个重要指标。

<img :src="$withBase('/image/⽹络延时.png')" alt="⽹络延时"/>

那建⽴TCP连接时，需要花费多少个RTT呢？

HTTP1.1和HTTP2.0都是使⽤TCP协议来传输的，⽽如果使⽤HTTPS的话，还需要使⽤TLS协议进⾏
安全传输，⽽使⽤TLS也需要⼀个握⼿过程，这样就需要有两个握⼿延迟过程。

1. 在建⽴TCP连接的时候，需要和服务器进⾏三次握⼿来确认连接成功，也就是说需要在消耗完1.5个RTT之后才能进⾏数据传输。
2. 进⾏TLS连接，TLS有两个版本⸺TLS1.2和TLS1.3，每个版本建⽴连接所花的时间不同，⼤致是需要1〜2个RTT，关于HTTPS我们到后⾯到安全模块再做详细介绍。

总之，在传输数据之前，我们需要花掉3〜4个RTT。如果浏览器和服务器的物理距离较近，那么1个RTT的时间可能在10毫秒以内，也就是说总共要消耗掉30〜40毫秒。这个时间也许⽤⼾还可以接受，但如果服务器相隔较远，那么1个RTT就可能需要100毫秒以上了，这种情况下整个握⼿过程需要300〜400毫秒，这时⽤⼾就能明显地感受到“慢”了。

### TCP协议僵化

既然TCP协议存在队头阻塞和建⽴连接延迟等缺点，那我们是不是可以通过改进TCP协议来解决
这些问题呢？

**几乎不行**

第⼀个是中间设备的僵化。要搞清楚什么是中间设备僵化，我们先要弄明⽩什么是中间设备。我们知道互联⽹是由多个⽹络互联的⽹状结构，为了能够保障互联⽹的正常⼯作，我们需要在互联⽹的各处搭建路由器、防⽕墙、NAT、交换机等各种设备，这些设备就被称为中间设备。

如果我们在客⼾端升级了TCP协议，但是当新协议的数据包经过这些没有更新的中间设备时，它们可能不理解包
的内容，于是这些数据就会被丢弃掉。这就是中间设备僵化，它是阻碍TCP更新的⼀⼤障碍。

除了中间设备僵化外，**操作系统也是导致TCP协议僵化的另外⼀个原因**。因为TCP协议都是通过操作系统内核来实现的，应⽤程序只能使⽤不能修改。通常操作系统的更新都滞后于软件的更新，因此要想⾃由地更新内核中的TCP协议也是⾮常困难的。

### QUIC协议

HTTP2.0存在⼀些⽐较严重的与TCP协议相关的缺陷，但由于TCP协议僵化，我们⼏乎不可能通过修改TCP协议⾃⾝来解决这些问题，那么解决问题的思路是绕过TCP协议，发明⼀个TCP和UDP之外的新的传输协议。但是这也⾯临着和修改TCP⼀样的挑战，因为中间设备的僵化，这些设备只认TCP和UDP，如果采⽤了新的协议，新协议在这些设备同样不被很好地⽀持。

因此，HTTP3.0选择了⼀个折衷的⽅法⸺UDP协议，基于UDP实现了类似于 TCP的多路数据流、传输可靠性等功能，我们把这套功能称为QUIC协议。关于HTTP2.0和HTTP3.0协议栈的⽐较，可以参考下图：
<img :src="$withBase('/image/HTTP2和HTTP3协议栈.png')" alt="HTTP2和HTTP3协议栈" height="300"/>

HTTP/3中的QUIC协议集合了以下⼏点功能:

+ 实现了类似TCP的流量控制、传输可靠性的功能。虽然UDP不提供可靠性的传输，但QUIC在UDP的基础之上增加了⼀层来保证数据可靠性传输。它提供了数据包重传、拥塞控制以及其他⼀些TCP中存在的特性。
+ 集成了TLS加密功能。⽬前QUIC使⽤的是TLS1.3，相较于早期版本TLS1.3有更多的优点，其中最重要的⼀点是减少了握⼿所花费的RTT个数。
+ 实现了HTTP/2中的多路复⽤功能。和TCP不同，QUIC实现了在同⼀物理连接上可以有多个独⽴的逻辑数据流（如下图）。实现了数据流的单独传输，就解决了TCP中队头阻塞的问题。

<img :src="$withBase('/image/QUIC协议的多路复⽤.png')" alt="QUIC协议的多路复⽤"/>

+ 实现了快速握⼿功能。由于QUIC是基于UDP的，所以QUIC可以实现使⽤0-RTT或者1-RTT来建⽴连接，这意味着QUIC可以⽤最快的速度来发送和接收数据，这样可以⼤⼤提升⾸次打开⻚⾯的速度。

### 艰难之路

通过上⾯的分析，我们相信在技术层⾯，HTTP/3是个完美的协议。不过要将HTTP/3应⽤到实际环境中依然⾯临着诸多严峻的挑战，这些挑战主要来⾃于以下三个⽅⾯。

+ 第⼀，从⽬前的情况来看，服务器和浏览器端都没有对HTTP/3提供⽐较完整的⽀持。Chrome虽然在数年前就开始⽀持Google版本的QUIC，但是这个版本的QUIC和官⽅的QUIC存在着⾮常⼤的差异。

+ 第⼆，部署HTTP/3也存在着⾮常⼤的问题。因为系统内核对UDP的优化远远没有达到TCP的优化程度，这也是阻碍QUIC的⼀个重要原因。

+ 第三，中间设备僵化的问题。这些设备对UDP的优化程度远远低于TCP，据统计使⽤QUIC协议时，⼤约有3%〜7%的丢包率。




